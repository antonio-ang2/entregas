# Ponderada Semana 5

# InformaÃ§Ãµes do Aluno  
Aluno | Curso | MÃ³dulo | Turma
:---: | :---: | :---: | :---:
Antonio Angelo Teixeira | Engenharia da ComputaÃ§Ã£o | 7 | 2

## Estrutura de Pastas
```
ğŸ“¦semana 7
 â”£ ğŸ“‚amb
 â”ƒ â”£ ğŸ“‚Include
 â”ƒ â”£ ğŸ“‚Lib
 â”ƒ â”£ ğŸ“‚Scripts
 â”ƒ â”£ ğŸ“‚share
 â”ƒ â”£ ğŸ“œpyvenv.cfg
 â”£ ğŸ“‚pages
 â”£ ğŸ“‚content
 â”£ ğŸ“œpyvenv.cfg
 â”£ ğŸ“œDockerfile
 â”£ ğŸ“œlogs.log
 â”£ ğŸ“œmain.py
 â”£ ğŸ“œminha_api.pkl
 â”£ ğŸ“œminha_api.py
 â”£ ğŸ“œmodelo_2.pkl
 â”£ ğŸ“œREAD.MD
 â”£ ğŸ“œrequirements.txt
 â”£ ğŸ“œstyle.css
```
## ExplicaÃ§Ã£o da Atividade
A atividade proposta demanda conceitos de alguns serviÃ§os AWS, machinelearning com Pycaret para Automl e streamlit para criaÃ§Ã£o de dahsboards para visualizaÃ§Ã£o das prediÃ§Ãµes realizadas. O objetivo Ã© enviar um arquivo CSV para a API de um  modelo machine learning gerado pelo Pycaret e retorna no formato JSON a prediÃ§Ã£o de cada linha do Parquet.
Consoante a isso, o arquivo parquet selecionado pelo aluno foi "Customer Segmentation". 

As colunas contidas nesse dataframe sÃ£o:
- CustomerID
- Gender 
- Age
- Annual Income (k$) - COLUNA RENOMEADA APENAS PARA "INCOME" POR MOTIVOS DE PRATICIDADE
- Spending Score (1-100) - COLUNA RENOMEADA APENAS PARA "SCORE" POR MOTIVOS DE PRATICIDADE

# Tecnologias usadas

As tecnologias usadas para essa ponderada sÃ£o listadas abaixo e descritas:
## Streamlit
Streamlit Ã© uma ferramenta Open Source que permite construir aplicaÃ§Ãµes web sem necessidade de conhecimentos avanÃ§ados em desenvolvimento frontend. No caso da ponderada, ele consome os dados diretamente do arquivo CSV na pÃ¡gina main.py.
AlÃ©m disso, a estrutura do streamlit contÃ©m um diretÃ³rio chamado pages, com o predict consumindo da API de prediÃ§Ã£o. 

Para visualizaÃ§Ã£o, optei por trÃªs grÃ¡ficos diferentes:

- GrÃ¡fico de comparaÃ§Ã£o de Age x Select data. Com essa Ãºltima variÃ¡vel podendo assumir dois valores: Income e Score

<p align="center">
<img src="(content/main_graph.png)">

<p align="center"> 1 â€” DemonstraÃ§Ã£o do processo manual de separaÃ§Ã£o de amostras realizado pelo IPT.</p>

</p>


**Link para o DockerHub**: https://hub.docker.com/repository/docker/antonioangelo2/entrega5/general

## Como Executar:
### Localmente
Para fazer o pull da imagem contida no dockerhub basta usar o seguinte comando no terminal: 
```docker push antonioangelo2/entrega5:tagname```

ApÃ³s isso, rode o comando ```docker images``` para garantir que a imagem estÃ¡ contida no docker.

Rode o comando ```docker run -d --name <nome-do-seu-container> -p 8000:8000 antonioangelo2/entrega5:v1.0``` para criar um container e rodÃ¡-lo, a fim de executar a aplicaÃ§Ã£o.

ApÃ³s isso, projeto pode ser acessado em **(http://localhost:8000)**

Pronto. tudo certo para requisitar uma prediÃ§Ã£o. Agora basta usar a URL do modelo com a API especÃ­fica (http://localhost:8000/predict).

O dataset escolhido trata-se de um dataset de score de gasto com base nas seguintes caracterÃ­sticas: gÃªnero, idade, Income(quanto de dinheiro esse consumidor ganha anualmente em milhares). Fora esses, o Id costumer tambÃ©m estava contido no dataset, porÃ©m, ao gerar o Pycaret, optei por ignorar essa feature, pois se trata de uma feature irrelevante ao modelo.
<br>

Por fim, para rodar o modelo, basta acessar um softare de teste de API, thunderclient, por exemplo, e passar um Json semelhante a essa na URL especÃ­fica do modelo
{
    "Gender": "Male",
    "Age": 30,
    "Income": 15
}

O resultado esperado Ã© um retorno de prediÃ§Ã£o do score de gasto.


